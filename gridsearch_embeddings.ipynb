{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-11 11:13:03,625 : INFO : ... loading the data...\n",
      "\n",
      "this is length of the dataframe: 3486\n",
      "2019-12-11 11:13:03,628 : INFO : Starting gridsearch CV..\n",
      "2019-12-11 11:13:03,629 : INFO : Classifier name: Passive Agressive\n",
      " classifier:PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              early_stopping=False, fit_intercept=True, loss='hinge',\n",
      "              max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
      "              random_state=None, shuffle=True, tol=None,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      " params{'clf__fit_intercept': (True, False), 'clf__C': (0.01, 0.5, 1.0), 'clf__loss': ('hinge', 'squared_hinge'), 'clf__max_iter': (5, 10, 15)}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded the vectorizer: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-11 11:16:17,097 : INFO : Passive Agressive score: 0.7865329512893983\n",
      "2019-12-11 11:16:17,099 : INFO : Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip...=None, shuffle=True, tol=None,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False))]) are the best estimators\n",
      "2019-12-11 11:16:17,464 : INFO : Created dictionary with classification report: \n",
      "\n",
      "{'1': {'precision': 0.8048780487804879, 'support': 113, 'recall': 0.8761061946902655, 'f1-score': 0.8389830508474576}, 'macro avg': {'precision': 0.7152860090825017, 'support': 698, 'recall': 0.7440394701102254, 'f1-score': 0.7280183321563088}, '4': {'precision': 0.5526315789473685, 'support': 64, 'recall': 0.65625, 'f1-score': 0.6}, 'vectorizer': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), 'classifier': 'Passive Agressive', 'weighted avg': {'precision': 0.7918216497601269, 'support': 698, 'recall': 0.7865329512893983, 'f1-score': 0.7882308301833596}, '3': {'precision': 0.8826666666666667, 'support': 393, 'recall': 0.8422391857506362, 'f1-score': 0.8619791666666667}, 'micro avg': {'precision': 0.7865329512893983, 'support': 698, 'recall': 0.7865329512893983, 'f1-score': 0.7865329512893983}, 'parameters': {'clf__fit_intercept': True, 'clf__C': 0.5, 'clf__loss': 'hinge', 'clf__max_iter': 15}, '2': {'precision': 0.6209677419354839, 'support': 128, 'recall': 0.6015625, 'f1-score': 0.611111111111111}}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-216388aa067c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;31m#\"w2v_count\", \"w2v_tfidf\", \"count\", \"tfidf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-216388aa067c>\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(path_to_data, path_to_embeddings, dataset, outputpath)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mclass_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridsearch_with_classifiers_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mfname_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}baseline_classreport.json'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-216388aa067c>\u001b[0m in \u001b[0;36mgridsearch_with_classifiers_baseline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Created dictionary with classification report: \\n\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_to_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mclass_report\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_to_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0my_hats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_report' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,  TfidfTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import logging\n",
    "import json\n",
    "from sklearn.svm import SVC\n",
    "import embeddingvectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import gensim\n",
    "import os\n",
    "\n",
    "\n",
    "path_to_embeddings='/home/anne/tmpanne/fullsample'\n",
    "path_to_data='/home/anne/tmpanne/AEM_data/'\n",
    "dataset = 'dataset_vermeer.pkl'\n",
    "outputpath = '/home/anne/tmpanne/AEM_output/'\n",
    "\n",
    "#word_embedding_path = '/home/anne/tmpanne/fullsample/'\n",
    "\n",
    "class classifier_analyzer():\n",
    "    \n",
    "    def __init__(self, path_to_data, path_to_embeddings, dataset):\n",
    "        self.nmodel = 0\n",
    "        df = pd.read_pickle(path_to_data + dataset)\n",
    "        logging.info(\"... loading the data...\\n\\nthis is length of the dataframe: {}\".format(len(df)))\n",
    "        self.test_size = 0.2\n",
    "        self.data = df['text']\n",
    "        self.labels = df['topic']\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data, self.labels, test_size=self.test_size, random_state=42)\n",
    "        self.basepath = path_to_embeddings\n",
    "        self.names = [\"Passive Agressive\", \"SGDClassifier\" , \"SVM\", \"ET\"]\n",
    "        self.classifiers = [PassiveAggressiveClassifier(), \n",
    "                            SGDClassifier(),\n",
    "                            SVC(),\n",
    "                            ExtraTreesClassifier() ]\n",
    "        self.parameters = [\n",
    "\n",
    "                    {'clf__loss': ('hinge', 'squared_hinge'),\n",
    "                    'clf__C': (0.01, 0.5, 1.0)   ,\n",
    "                    'clf__fit_intercept': (True, False) ,\n",
    "                    #'vect__ngram_range': [(1, 1), (1, 2)] ,\n",
    "                #    'tfidf__use_idf' :(True ,False),\n",
    "                    'clf__max_iter': (5 ,10 ,15) } ,\n",
    "\n",
    "                    {'clf__max_iter': (20, 30) ,\n",
    "                    'clf__alpha': (1e-2, 1e-3, 1e-5),\n",
    "                    'clf__penalty': ('l2', 'elasticnet')} ,\n",
    "\n",
    "                    {'clf__C': [1, 10, 100, 1000],\n",
    "                    'clf__gamma': [0.001, 0.0001],\n",
    "                    'clf__kernel': ['rbf', 'linear']},\n",
    "\n",
    "\n",
    "                    { \"clf__max_features\": ['auto', 'sqrt', 'log2'] }\n",
    "\n",
    "                     ]\n",
    "\n",
    "\n",
    "    def get_w2v_model(self):\n",
    "            '''yields a dict with one item. key is the filename, value the gensim model'''\n",
    "\n",
    "            filenames = [e for e in os.listdir(self.basepath) if not e.startswith('.')]\n",
    "\n",
    "            for fname in filenames:\n",
    "                model = {}\n",
    "                path = os.path.join(self.basepath, fname)\n",
    "                print(\"\\nLoading gensim model\")\n",
    "\n",
    "                if fname.startswith('w2v'):\n",
    "                    mod = gensim.models.Word2Vec.load(path)\n",
    "                else:\n",
    "                    mod = gensim.models.KeyedVectors.load_word2vec_format(path)\n",
    "\n",
    "                model['gensimmodel'] = dict(zip(mod.wv.index2word, mod.wv.vectors))\n",
    "                model['filename'] = fname\n",
    "                self.nmodel +=1\n",
    "                print(\"loaded gensim model nr {}, named: {}\".format(self.nmodel, model['filename']))\n",
    "                yield model\n",
    "\n",
    "\n",
    "    def get_vectorizer(self, vectorizer, model):\n",
    "        logging.info(\"the vectorizer is: {}\".format(vectorizer))\n",
    "        \n",
    "       # if self.vectorizer == 'tfidf':\n",
    "       #     VECT = TfidfVectorizer()\n",
    "\n",
    "      #  elif self.vectorizer == 'count':\n",
    "      #      VECT = CountVectorizer\n",
    "            \n",
    "           # logging.info('... Loading W2V model....:{}'.format(self.model['filename']))\n",
    "        vec = {}   \n",
    "        vec['filename'] = vectorizer\n",
    "        if vectorizer == 'w2v_count':\n",
    "            s = embeddingvectorizer.EmbeddingCountVectorizer(model['gensimmodel'], 'mean')\n",
    "        elif vectorizer == 'w2v_tfidf':\n",
    "            s = embeddingvectorizer.EmbeddingTfidfVectorizer(model['gensimmodel'], 'mean')\n",
    "        vec['vectorizer'] = s\n",
    "        print(\"loaded vectorizer, named: {}\".format(vec['filename']))\n",
    "\n",
    "        yield vec\n",
    "\n",
    "\n",
    "    def gridsearch_with_classifiers_embeddings(self):\n",
    "        class_report = []\n",
    "        results = []\n",
    "        \n",
    "        for model in self.get_w2v_model():\n",
    "            for v in [\"w2v_count\", \"w2v_tfidf\"]:\n",
    "                for vec in self.get_vectorizer(v, model):\n",
    "                    print(\"loaded the vectorizer: {}\".format(vec['filename'])) \n",
    "                    for name, classifier, params in zip(self.names, self.classifiers, self.parameters):\n",
    "                        my_dict = {}\n",
    "                        \n",
    "                        logging.info(\"Starting gridsearch CV..\")\n",
    "                        logging.info(\"Classifier name: {}\\n classifier:{}\\n params{}\\n\".format(name, classifier, params)) \n",
    "\n",
    "                        clf_pipe = Pipeline([ ('vect', vec['vectorizer']), ('clf', classifier), ])\n",
    "\n",
    "                        gs_clf = GridSearchCV(clf_pipe, param_grid=params, cv=2)\n",
    "                        clf = gs_clf.fit(self.X_train, self.y_train)\n",
    "                        score = clf.score(self.X_test, self.y_test)\n",
    "\n",
    "                        logging.info(\"{} score: {}\".format(name, score))\n",
    "                        logging.info(\"{} are the best estimators\".format(clf.best_estimator_))\n",
    "\n",
    "                        results_to_dict = classification_report((clf.best_estimator_.predict(self.X_test)), self.y_test, output_dict= True)\n",
    "\n",
    "                        results_to_dict['classifier'] = name\n",
    "                        results_to_dict['parameters'] = clf.best_params_\n",
    "                        results_to_dict['vectorizer'] = vec['filename']\n",
    "                        results_to_dict['model'] = model['filename']\n",
    "\n",
    "                        logging.info(\"Created dictionary with classification report: \\n\\n{}\".format(results_to_dict))\n",
    "                        class_report.append(results_to_dict)\n",
    "                        \n",
    "                        y_hats = clf.predict(self.X_test)\n",
    "                        results.append({\"predicted\": y_hats,\n",
    "                                        \"actual\" : self.y_test.values  ,\n",
    "                                        \"classifier\": name} )\n",
    "                        \n",
    "        return class_report, results\n",
    "\n",
    "    def gridsearch_with_classifiers_baseline(self):\n",
    "        \n",
    "        for vec in [CountVectorizer(), TfidfVectorizer()]:\n",
    "            print(\"loaded the vectorizer: {}\".format(vec)) \n",
    "            for name, classifier, params in zip(self.names, self.classifiers, self.parameters):\n",
    "                my_dict = {}\n",
    "\n",
    "                logging.info(\"Starting gridsearch CV..\")\n",
    "                logging.info(\"Classifier name: {}\\n classifier:{}\\n params{}\\n\".format(name, classifier, params)) \n",
    "\n",
    "                clf_pipe = Pipeline([ ('vect', vec), ('clf', classifier), ])\n",
    "\n",
    "                gs_clf = GridSearchCV(clf_pipe, param_grid=params, cv=2)\n",
    "                clf = gs_clf.fit(self.X_train, self.y_train)\n",
    "                score = clf.score(self.X_test, self.y_test)\n",
    "\n",
    "                logging.info(\"{} score: {}\".format(name, score))\n",
    "                logging.info(\"{} are the best estimators\".format(clf.best_estimator_))\n",
    "\n",
    "                results_to_dict = classification_report((clf.best_estimator_.predict(self.X_test)), self.y_test, output_dict= True)\n",
    "\n",
    "                results_to_dict['classifier'] = name\n",
    "                results_to_dict['parameters'] = clf.best_params_\n",
    "                results_to_dict['vectorizer'] = vec\n",
    "                \n",
    "                logging.info(\"Created dictionary with classification report: \\n\\n{}\".format(results_to_dict))\n",
    "                class_report.append(results_to_dict)\n",
    "\n",
    "                y_hats = clf.predict(self.X_test)\n",
    "                results.append({\"predicted\": y_hats,\n",
    "                                \"actual\" : self.y_test.values  ,\n",
    "                                \"classifier\": name} )\n",
    "\n",
    "\n",
    "def get_scores(path_to_data, path_to_embeddings, dataset, outputpath):\n",
    "    a = classifier_analyzer(path_to_data=path_to_data, path_to_embeddings=path_to_embeddings, dataset=dataset)\n",
    "    class_report, results = a.gridsearch_with_classifiers_baseline()\n",
    "\n",
    "    fname_accuracy = '{}baseline_classreport.json'.format(outputpath)\n",
    "    fname_true_predicted = '{}baseline_true_predicted.json'.format(outputpath)\n",
    "\n",
    "    with open(fname_accuracy, mode = 'w') as fo:\n",
    "        json.dump(class_report, fo)\n",
    "\n",
    "    data = pd.DataFrame.from_dict(results)\n",
    "\n",
    "    predicted = data.predicted.apply(pd.Series).merge(data, right_index = True, left_index = True) \\\n",
    "        .drop([\"predicted\"], axis = 1).melt(id_vars = ['classifier'], value_name = \"Predicted label\")\n",
    "\n",
    "    actual = data.actual.apply(pd.Series).merge(data, right_index = True, left_index = True) \\\n",
    "        .drop([\"predicted\"], axis = 1).melt(id_vars = ['classifier'], value_name = \"Actual label\")\n",
    "\n",
    "    df = pd.merge(predicted, actual, how = 'inner', left_index = True, right_index = True)\n",
    "    \n",
    "    df['Classifier'] = df['classifier_x']\n",
    "    df = df[df.variable_x != 'actual']\n",
    "    df = df[['Predicted label', 'Actual label', 'Classifier']]\n",
    "\n",
    "    df.to_json(fname_true_predicted)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "    logging.root.setLevel(level=logging.INFO)\n",
    "    \n",
    "    get_scores(path_to_embeddings=path_to_embeddings,path_to_data=path_to_data, dataset=dataset, outputpath = outputpath)\n",
    "\n",
    "#\"w2v_count\", \"w2v_tfidf\", \"count\", \"tfidf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "for vec in [CountVectorizer(), TfidfVectorizer()]:\n",
    "    print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_embeddings='/home/anne/tmpanne/AEM_small_sample/test'\n",
    "path_to_data='/home/anne/tmpanne/AEM_data/'\n",
    "#dataset = 'dataset_burscher.pkl'\n",
    "dataset = 'dataset_vermeer.pkl'\n",
    "outputpath = '/home/anne/tmpanne/AEM_output/'\n",
    "\n",
    "a = classifier_analyzer(path_to_data=path_to_data, path_to_embeddings= path_to_embeddings, dataset = dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report, results = a.gridsearch_with_classifiers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(path_to_data, path_to_embeddings, dataset, outputpath):\n",
    "    a = classifier_analyzer(path_to_data=path_to_data, path_to_embeddings=path_to_embeddings, dataset=dataset)\n",
    "    class_report, results = a.gridsearch_with_classifiers()\n",
    "    \n",
    "    fname_accuracy = '{}classreport.json'.format(outputpath)\n",
    "    fname_predictions = '{}SML_predicted_actual_text_cleaned.json'.format(outputpath)\n",
    "\n",
    "    with open(fname_accuracy, mode = 'w') as fo:\n",
    "        json.dump(class_report, fo)\n",
    "\n",
    "    data = pd.DataFrame.from_dict(results)\n",
    "\n",
    "    predicted = data.predicted.apply(pd.Series).merge(data, right_index = True, left_index = True) \\\n",
    "        .drop([\"predicted\"], axis = 1).melt(id_vars = ['classifier'], value_name = \"Predicted label\")\n",
    "\n",
    "    actual = data.actual.apply(pd.Series).merge(data, right_index = True, left_index = True) \\\n",
    "        .drop([\"predicted\"], axis = 1).melt(id_vars = ['classifier'], value_name = \"Actual label\")\n",
    "\n",
    "    df = pd.merge(predicted, actual, how = 'inner', left_index = True, right_index = True)\n",
    "\n",
    "    df['Classifier'] = df['classifier_x']\n",
    "    df = df[df.variable_x != 'actual']\n",
    "    df = df[['Predicted label', 'Actual label', 'Classifier']]\n",
    "\n",
    "    df.to_json(fname_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(results)\n",
    "\n",
    "predicted = data.predicted.apply(pd.Series) \\\n",
    "    .merge(data, right_index = True, left_index = True) \\\n",
    "    .drop([\"predicted\"], axis = 1) \\\n",
    "    .melt(id_vars = ['classifier'], value_name = \"Predicted label\")\n",
    "\n",
    "actual = data.actual.apply(pd.Series) \\\n",
    "    .merge(data, right_index = True, left_index = True) \\\n",
    "    .drop([\"predicted\"], axis = 1) \\\n",
    "    .melt(id_vars = ['classifier'], value_name = \"Actual label\")\n",
    "\n",
    "df = pd.merge(predicted, actual, how = 'inner', left_index = True, right_index = True)\n",
    "\n",
    "df['Classifier'] = df['classifier_x']\n",
    "df = df[df.variable_x != 'actual']\n",
    "df = df[['Predicted label', 'Actual label', 'Classifier']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "    logging.root.setLevel(level=logging.INFO)\n",
    "\n",
    "    get_scores(sample=\"newspaper_sample_only\", vect = \"count\")\n",
    "    get_scores(sample=\"pq_sample_only\", vect = \"count\")\n",
    "    get_scores(sample=\"RPA_sample\", vect = \"count\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Parsing data...')\n",
    "parser.add_argument('--word_embedding_path', type=str, required=True, help='Path of pretrained word embedding.')\n",
    "parser.add_argument('--data_path', type=str, required=False, default='data/dataset_vermeer.pkl', help='Path of dataset with annotated data to be classified')\n",
    "parser.add_argument('--output', type=str, required=False, default='tables_figures/', help='Path of output file (CSV formatted classification scores)')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('Arguments:')\n",
    "print('word_embedding.path:', args.word_embedding_path)\n",
    "print('output.path:', args.output)\n",
    "print('data.path:', args.data_path)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,  TfidfTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import logging\n",
    "import json\n",
    "from sklearn.svm import SVC\n",
    "import embeddingvectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import gensim\n",
    "import os\n",
    "\n",
    "\n",
    "path_to_embeddings='/home/anne/tmpanne/fullsample'\n",
    "path_to_data='/home/anne/tmpanne/AEM_data/'\n",
    "dataset = 'dataset_vermeer.pkl'\n",
    "outputpath = '/home/anne/tmpanne/AEM_output/'\n",
    "\n",
    "#word_embedding_path = '/home/anne/tmpanne/fullsample/'\n",
    "\n",
    "class classifier_analyzer():\n",
    "    \n",
    "    def __init__(self, path_to_data, path_to_embeddings, dataset):\n",
    "        self.nmodel = 0\n",
    "        df = pd.read_pickle(path_to_data + dataset)\n",
    "        \n",
    "        logging.info(\"... loading the data...\\n\\nthis is length of the dataframe: {}\".format(len(df)))\n",
    "        self.test_size = 0.2\n",
    "        self.data = df['text']\n",
    "        self.labels = df['topic']\n",
    "        \n",
    "        # validation data\n",
    "        \n",
    "        self.train, self.test = train_test_split(self.data, self.labels, test_size = 0.1)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data, self.labels, test_size=self.test_size, random_state=42)\n",
    "        \n",
    "        self.basepath = path_to_embeddings\n",
    "        self.names = [\"Passive Agressive\", \"SGDClassifier\" , \"SVM\", \"ET\"]\n",
    "        self.classifiers = [PassiveAggressiveClassifier(), \n",
    "                            SGDClassifier(),\n",
    "                            SVC(),\n",
    "                            ExtraTreesClassifier() ]\n",
    "        self.parameters = [\n",
    "\n",
    "                    {'clf__loss': ('hinge', 'squared_hinge'),\n",
    "                    'clf__C': (0.01, 0.5, 1.0)   ,\n",
    "                    'clf__fit_intercept': (True, False) ,\n",
    "                    #'vect__ngram_range': [(1, 1), (1, 2)] ,\n",
    "                #    'tfidf__use_idf' :(True ,False),\n",
    "                    'clf__max_iter': (5 ,10 ,15) } ,\n",
    "\n",
    "                    {'clf__max_iter': (20, 30) ,\n",
    "                    'clf__alpha': (1e-2, 1e-3, 1e-5),\n",
    "                    'clf__penalty': ('l2', 'elasticnet')} ,\n",
    "\n",
    "                    {'clf__C': [1, 10, 100, 1000],\n",
    "                    'clf__gamma': [0.001, 0.0001],\n",
    "                    'clf__kernel': ['rbf', 'linear']},\n",
    "\n",
    "\n",
    "                    { \"clf__max_features\": ['auto', 'sqrt', 'log2'] }\n",
    "\n",
    "                     ]\n",
    "\n",
    "\n",
    "    def get_w2v_model(self):\n",
    "            '''yields a dict with one item. key is the filename, value the gensim model'''\n",
    "\n",
    "            filenames = [e for e in os.listdir(self.basepath) if not e.startswith('.')]\n",
    "\n",
    "            for fname in filenames:\n",
    "                model = {}\n",
    "                path = os.path.join(self.basepath, fname)\n",
    "                print(\"\\nLoading gensim model\")\n",
    "\n",
    "                if fname.startswith('w2v'):\n",
    "                    mod = gensim.models.Word2Vec.load(path)\n",
    "                else:\n",
    "                    mod = gensim.models.KeyedVectors.load_word2vec_format(path)\n",
    "\n",
    "                model['gensimmodel'] = dict(zip(mod.wv.index2word, mod.wv.vectors))\n",
    "                model['filename'] = fname\n",
    "                self.nmodel +=1\n",
    "                print(\"loaded gensim model nr {}, named: {}\".format(self.nmodel, model['filename']))\n",
    "                yield model\n",
    "\n",
    "\n",
    "    def get_vectorizer(self, vectorizer, model):\n",
    "        logging.info(\"the vectorizer is: {}\".format(vectorizer))\n",
    "        \n",
    "       # if self.vectorizer == 'tfidf':\n",
    "       #     VECT = TfidfVectorizer()\n",
    "\n",
    "      #  elif self.vectorizer == 'count':\n",
    "      #      VECT = CountVectorizer\n",
    "            \n",
    "           # logging.info('... Loading W2V model....:{}'.format(self.model['filename']))\n",
    "        vec = {}   \n",
    "        vec['filename'] = vectorizer\n",
    "        if vectorizer == 'w2v_count':\n",
    "            s = embeddingvectorizer.EmbeddingCountVectorizer(model['gensimmodel'], 'mean')\n",
    "        elif vectorizer == 'w2v_tfidf':\n",
    "            s = embeddingvectorizer.EmbeddingTfidfVectorizer(model['gensimmodel'], 'mean')\n",
    "        vec['vectorizer'] = s\n",
    "        print(\"loaded vectorizer, named: {}\".format(vec['filename']))\n",
    "        yield vec\n",
    "\n",
    "\n",
    "    def gridsearch_with_classifiers_embeddings(self):\n",
    "        class_report = []\n",
    "        results = []\n",
    "        \n",
    "        for model in self.get_w2v_model():\n",
    "            for v in [\"w2v_count\", \"w2v_tfidf\"]:\n",
    "                for vec in self.get_vectorizer(v, model):\n",
    "                    print(\"loaded the vectorizer: {}\".format(vec['filename'])) \n",
    "                    for name, classifier, params in zip(self.names, self.classifiers, self.parameters):\n",
    "                        my_dict = {}\n",
    "                        \n",
    "                        logging.info(\"Starting gridsearch CV..\")\n",
    "                        logging.info(\"Classifier name: {}\\n classifier:{}\\n params{}\\n\".format(name, classifier, params)) \n",
    "\n",
    "                        clf_pipe = Pipeline([ ('vect', vec['vectorizer']), ('clf', classifier), ])\n",
    "\n",
    "                        gs_clf = GridSearchCV(clf_pipe, param_grid=params, cv=2)\n",
    "                        clf = gs_clf.fit(self.X_train, self.y_train)\n",
    "                        score = clf.score(self.X_test, self.y_test)\n",
    "\n",
    "                        logging.info(\"{} score: {}\".format(name, score))\n",
    "                        logging.info(\"{} are the best estimators\".format(clf.best_estimator_))\n",
    "\n",
    "                        results_to_dict = classification_report((clf.best_estimator_.predict(self.X_test)), self.y_test, output_dict= True)\n",
    "\n",
    "                        results_to_dict['classifier'] = name\n",
    "                        results_to_dict['parameters'] = clf.best_params_\n",
    "                        results_to_dict['vectorizer'] = vec['filename']\n",
    "                        results_to_dict['model'] = model['filename']\n",
    "\n",
    "                        logging.info(\"Created dictionary with classification report: \\n\\n{}\".format(results_to_dict))\n",
    "                        class_report.append(results_to_dict)\n",
    "                        \n",
    "                        y_hats = clf.predict(self.X_test)\n",
    "                        results.append({\"predicted\": y_hats,\n",
    "                                        \"actual\" : self.y_test.values  ,\n",
    "                                        \"classifier\": name} )\n",
    "                        \n",
    "        return class_report, results\n",
    "\n",
    "    def gridsearch_with_classifiers_baseline(self):\n",
    "        class_report = []\n",
    "        results = []\n",
    "        \n",
    "        for vec, n in zip([CountVectorizer(), TfidfVectorizer()], [\"Count\", \"TfidF\"]):\n",
    "            \n",
    "            print(\"loaded the vectorizer: {}\\n\\n\\{}\".format(n, vec)) \n",
    "            \n",
    "            for name, classifier, params in zip(self.names, self.classifiers, self.parameters):\n",
    "                my_dict = {}\n",
    "\n",
    "                logging.info(\"Starting gridsearch CV..\")\n",
    "                logging.info(\"Classifier name: {}\\n classifier:{}\\n params{}\\n\".format(name, classifier, params)) \n",
    "\n",
    "                clf_pipe = Pipeline([ ('vect', vec), ('clf', classifier), ])\n",
    "\n",
    "                gs_clf = GridSearchCV(clf_pipe, param_grid=params, cv=2)\n",
    "                clf = gs_clf.fit(self.X_train, self.y_train)\n",
    "                score = clf.score(self.X_test, self.y_test)\n",
    "\n",
    "                logging.info(\"{} score: {}\".format(name, score))\n",
    "                logging.info(\"{} are the best estimators\".format(clf.best_estimator_))\n",
    "\n",
    "                results_to_dict = classification_report((clf.best_estimator_.predict(self.X_test)), self.y_test, output_dict= True)\n",
    "\n",
    "                results_to_dict['classifier'] = name\n",
    "                results_to_dict['parameters'] = clf.best_params_\n",
    "                results_to_dict['vectorizer'] = n\n",
    "                results_to_dict['model'] = \"baseline\"\n",
    "                \n",
    "                logging.info(\"Created dictionary with classification report: \\n\\n{}\".format(results_to_dict))\n",
    "                class_report.append(results_to_dict)\n",
    "\n",
    "                y_hats = clf.predict(self.X_test)\n",
    "                results.append({\"predicted\": y_hats,\n",
    "                                \"actual\" : self.y_test.values  ,\n",
    "                                \"classifier\": name} )\n",
    "                \n",
    "        return class_report, results\n",
    "\n",
    "\n",
    "def get_scores(path_to_data, path_to_embeddings, dataset, outputpath):\n",
    "    a = classifier_analyzer(path_to_data=path_to_data, path_to_embeddings=path_to_embeddings, dataset=dataset)\n",
    "    class_report, results = a.gridsearch_with_classifiers_baseline()\n",
    "\n",
    "    fname_accuracy = '{}baseline_classreport.json'.format(outputpath)\n",
    "    fname_true_predicted = '{}baseline_true_predicted.json'.format(outputpath)\n",
    "\n",
    "    with open(fname_accuracy, mode = 'w') as fo:\n",
    "        json.dump(class_report, fo)\n",
    "\n",
    "    data = pd.DataFrame.from_dict(results)\n",
    "\n",
    "    predicted = data.predicted.apply(pd.Series).merge(data, right_index = True, left_index = True) \\\n",
    "        .drop([\"predicted\"], axis = 1).melt(id_vars = ['classifier'], value_name = \"Predicted label\")\n",
    "\n",
    "    actual = data.actual.apply(pd.Series).merge(data, right_index = True, left_index = True) \\\n",
    "        .drop([\"predicted\"], axis = 1).melt(id_vars = ['classifier'], value_name = \"Actual label\")\n",
    "\n",
    "    df = pd.merge(predicted, actual, how = 'inner', left_index = True, right_index = True)\n",
    "    \n",
    "    df['Classifier'] = df['classifier_x']\n",
    "    df = df[df.variable_x != 'actual']\n",
    "    df = df[['Predicted label', 'Actual label', 'Classifier']]\n",
    "\n",
    "    df.to_json(fname_true_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-686bf35a54ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data, self.labels, test_size=self.test_size, random_state=42)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(path_to_data + dataset)\n",
    "test_size = 0.2\n",
    "data = df['text']\n",
    "labels = df['topic']\n",
    "# validation data\n",
    "data, validation_set = train_test_split(data, labels, test_size = 0.1)\n",
    "#self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data, self.labels, test_size=self.test_size, random_state=42)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "    logging.root.setLevel(level=logging.INFO)\n",
    "    \n",
    "    get_scores(path_to_embeddings=path_to_embeddings,path_to_data=path_to_data, dataset=dataset, outputpath = outputpath)\n",
    "\n",
    "#\"w2v_count\", \"w2v_tfidf\", \"count\", \"tfidf\"\n",
    "\n",
    "print(\"DOOOOOOOOOOOOONEEE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
